# GPT-3

Generative Pre-trained Transformer 3 (GPT-3)는 deep learning 언어모델입니다. 

## 파라메터

- 모델 파라메터(Traninable parameter)가 175 Billion (1,750억개)로 방대한 처리량을 요구합니다.
- 96개의 attention layer를 가집니다.
- 3.2M batch size를 가지고 있습니다. 

![image](https://user-images.githubusercontent.com/52392004/213849423-3424dda1-4a42-4dd2-87bf-4aae59976455.png)

GPT-3에 대한 모델정보입니다.

![image](https://user-images.githubusercontent.com/52392004/213849450-4b9e7fe4-9789-4d35-8af8-0e83a6c847bc.png)

변환하는것에 대한 순서도입니다.

![image](https://user-images.githubusercontent.com/52392004/213849682-72514952-87aa-4b90-b014-6cac07d792ae.png)



## Reference

[OpenAI GPT-3: Everything You Need to Know](https://www.springboard.com/blog/data-science/machine-learning-gpt-3-open-ai/)
